{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kamień milowy 3 (Finalne modele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congressional_voting_df = pd.read_csv(\"congressional_voting_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmieniamy kodowanie zmiennych\n",
    "# teraz traktujemy \"?\" jako wsztrzymania się od głosu, a nie brak danych\n",
    "map = {\"y\": 1, \"n\" : -1, \"?\": 0, \"democrat\" : 1, \"republican\" : 0}\n",
    "# map = {\"y\": 2, \"n\" : 1, \"?\": 0, \"democrat\" : 1, \"republican\" : 0} # przy takim kodowaniu wyniki są gorsze\n",
    "\n",
    "columns = congressional_voting_df.columns.to_list()\n",
    "for column in columns:\n",
    "    congressional_voting_df[column] = congressional_voting_df[column].map(map)\n",
    "\n",
    "congressional_voting_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z kamienia 2 pamiętamy, że target jest zrównoważony\n",
    "X_train, X_test, y_train, y_test = train_test_split(congressional_voting_df.drop(\"political_party\", axis=1), \n",
    "                                                    congressional_voting_df[\"political_party\"], \n",
    "                                                    test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling(all variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"rfc\": 0,\n",
    "    \"xgb\": 1, # eXtreme gradient boosting\n",
    "    \"gbc\": 2, # gradient boosting\n",
    "    \"lr\": 3\n",
    "}\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'bootstrap': [True, False],\n",
    "        'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'max_depth': [6, 10, 15, 20],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "        'gamma': [0, 0.25, 0.5, 1.0],\n",
    "        'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "        'n_estimators': [100]},\n",
    "    \n",
    "    {\n",
    "        'n_estimators': [100, 300, 500, 700, 900, 1200, 1500, 1700, 2000],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        'max_depth': [4, 6, 8, 10]\n",
    "        \n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'penalty' : ['l1', 'l2'],\n",
    "        'C' : np.logspace(-4, 4, 20),\n",
    "        'solver' : ['liblinear', 'saga']}\n",
    "]\n",
    "\n",
    "models = [RandomForestClassifier(random_state=42),\n",
    "          XGBClassifier(use_label_encoder=False),\n",
    "          GradientBoostingClassifier(random_state=0),\n",
    "          LogisticRegression(random_state=0)\n",
    "         ]\n",
    "\n",
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(clf, X_test, y_test, model_type):\n",
    "    return pd.DataFrame({\n",
    "                            \"clf\": [model_type],\n",
    "                            \"accuracy\": [clf.score(X_test, y_test)], \n",
    "                            \"auc\": [roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])]\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(X_train, y_train, X_test, y_test, model_type):\n",
    "    if model_type == \"baseline\":\n",
    "        lr = LogisticRegression(random_state=0)\n",
    "        lr.fit(X_train, y_train)\n",
    "        return (lr, get_scores(lr, X_test, y_test, model_type))\n",
    "    \n",
    "    clf = models[models_dict[model_type]]\n",
    "    parameter_set = params[models_dict[model_type]]\n",
    "    \n",
    "    random_search = RandomizedSearchCV(clf, parameter_set, random_state=0, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    clf = random_search.best_estimator_\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return (clf, get_scores(clf, X_test, y_test, model_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_res_to_df(res):\n",
    "    res_merged = None\n",
    "\n",
    "    for i in range(len(res)):\n",
    "        res_merged = pd.concat([res_merged, res[i]], axis=0).reset_index(drop=True)\n",
    "        \n",
    "    return res_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline, baseline_scores = modeling(X_train, y_train, X_test, y_test, \"baseline\")\n",
    "res.append(baseline_scores)\n",
    "baseline_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc, rfc_scores = modeling(X_train, y_train, X_test, y_test, \"rfc\")\n",
    "res.append(rfc_scores)\n",
    "rfc_scores # gorzej niż baseline..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb, xgb_scores = modeling(X_train, y_train, X_test, y_test, \"xgb\")\n",
    "res.append(xgb_scores)\n",
    "xgb_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc, gbc_scores = modeling(X_train, y_train, X_test, y_test, \"gbc\")\n",
    "res.append(gbc_scores)\n",
    "gbc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, lr_scores = modeling(X_train, y_train, X_test, y_test, \"lr\")\n",
    "res.append(lr_scores)\n",
    "lr_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All variables\n",
    "Ogólnie lepiej niż 0.98... się nie daje. W porównaniu do kamienia 2 wyniki się nieco polepszyły, prawdopodobnie z powodu zmiany encodingu(i zrezygnowania z imputacji `?`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_res_to_df(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
